# 中国MOE与多模态大模型研究资源汇总

## 项目概述

本项目旨在系统梳理中国国内研究MoE（Mixture of Experts）和多模态大模型的主要导师、实验室和研究机构，为相关领域的研究者和申请者提供参考指南。

## 目录结构

```
minimaxi/
├── 01_moe_导师/              # MOE相关导师和实验室信息
│   └── 01_中国高校MoE研究汇总.md
├── 02_多模态_导师/           # 多模态大模型导师和实验室信息
│   └── 01_中国多模态大模型研究团队.md
├── 03_开源项目/              # GitHub开源项目收集
│   └── (待补充)
├── 04_研究机构/              # 主要AI研究机构详细信息
│   └── (待补充)
└── 05_综合报告/              # 综合整理报告
    └── 00_项目概览.md        # 本文件
```

## 已收录机构

### 顶尖高校AI实验室

| 机构 | 特色方向 | 核心教授 | 代表性工作 |
|------|---------|---------|-----------|
| 清华大学 | 机器学习理论、大模型系统 | 朱军、唐杰、刘知远 | CogView、知识增强模型 |
| 北京大学 | 多模态学习、CV+NLP | 王亦洲、刘田、穗志方 | 视觉Transformer、中文NLP |
| 南京大学 | 机器学习理论 | 周志华 | 深度森林、集成学习 |

### 主要研究机构

| 机构 | 研究重点 | 技术特色 |
|-------|---------|---------|
| 智源研究院 | 万亿级大模型 | 悟道1.0/2.0/3.0 |
| 上海AI Lab | 通用AI、多模态 | InternLM、MOSS、InternVL |
| 中科院计算所 | 高性能计算、AI系统 | 申威处理器、分布式训练 |
| 中科院自动化所 | 模式识别、多模态 | 视觉-语言模型、类脑智能 |

### 企业研究力量

| 企业 | 代表性模型 | 研究特色 |
|------|-----------|---------|
| 智谱AI | ChatGLM、VisualGLM | 产学研深度合作 |
| 阿里达摩院 | Qwen-VL、Qwen | 大规模预训练与产业应用 |
| 华为诺亚 | 盘古大模型 | 端云协同与硬件优化 |

## 研究方向分布

### MOE相关研究
1. **稀疏激活机制**：清华、中科院计算所
2. **多模态融合**：北大、上海AI Lab
3. **大规模训练系统**：华为诺亚、阿里达摩院
4. **理论分析**：南大LAMDA、清华朱军组

### 多模态大模型研究
1. **视觉语言预训练**：清华智谱团队、上海AI Lab
2. **具身智能**：浙大、上海AI Lab
3. **跨模态生成**：智谱AI、阿里达摩院
4. **多模态评测**：各大高校联合评测基准

## 招生与联系方式

### 最佳联系时间
- **推免生**：每年9-10月
- **考研**：每年12月
- **博士申请**：春季/秋季学期

### 建议渠道
1. 导师个人主页
2. 实验室官网
3. Google Scholar
4. AI学术会议
5. 各高校研究生招生网

## 重要提醒

⚠️ **信息时效性**：建议直接访问官方网站获取最新信息
⚠️ **研究方向匹配**：建议先阅读导师近期论文再联系
⚠️ **招生季节**：关注各高校推免和考研招生季

## 更新日志

- **2026-02-12**：初始版本，完成MOE导师和多模态导师两个核心模块
- **待补充**：开源项目、研究机构详细信息

## 贡献指南

如需补充或修正信息，请：
1. 在对应目录下创建新文件
2. 按照已有格式整理信息
3. 提交PR或联系项目维护者

---

**项目维护**：自动整理
**最后更新**：2026-02-12
**版本**：1.0
