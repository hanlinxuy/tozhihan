# Visual Token Compression Papers 2025 - Affiliations and Citations

## Summary of Findings

### ICCV 2025 Papers

| # | Paper Title | First Author | Affiliation | Type | arXiv ID | Citations* |
|---|-------------|--------------|-------------|------|----------|------------|
| 1 | FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers | Renshan Zhang | Shandong University (China) | Academia | 2501.16297 | 16 (GS) |
| 2 | Oasis: One Image is All You Need for Multimodal Instruction Data Synthesis | - | Not found on arXiv | - | - | - |
| 3 | Growing a Twig to Accelerate Large Vision-Language Models | Zhenwei Shao | University of Science and Technology of China (USTC) | Academia | 2503.14075 | - |
| 4 | Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs | Jeongseok Hyun | Yonsei University (South Korea) | Academia | 2507.07990 | - |
| 5 | Dynamic-VLM: Simple Dynamic Visual Token Compression for VideoLLM | Han Wang | ByteDance | Industry | 2412.09530 | - |

### CVPR 2025 Papers

| # | Paper Title | First Author | Affiliation | Type | arXiv ID | Citations* |
|---|-------------|--------------|-------------|------|----------|------------|
| 1 | LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant | Wei Li | Harbin Institute of Technology | Academia | 2503.03663 | - |
| 2 | A Stitch in Time Saves Nine: Small VLM is a Precise Guidance for Accelerating Large VLMs | Wangbo Zhao | National University of Singapore | Academia | 2412.03324 | - |
| 3 | PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction | Long Xing | Shanghai AI Lab / CUHK | Academia/Industry | 2410.17247 | - |
| 4 | Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models | Zhihang Liu | Zhejiang University | Academia | 2503.16036 | - |
| 5 | PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models | Mohamed Dhouib | Telecom Paris / IP Paris | Academia | 2504.08966 | - |
| 6 | DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models | Saeed Ranjbar Alvar | Huawei Noah's Ark Lab | Industry | 2503.02175 | - |
| 7 | SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding | Hao Li | CUHK / Shanghai AI Lab | Academia | 2412.09604 | - |
| 8 | PVC: Progressive Visual Token Compression for Unified Image and Video Processing in Large Vision-Language Models | Chenyu Yang | CUHK / Shanghai AI Lab | Academia | 2412.09613 | - |
| 9 | TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model | Cheng Yang | Rice University / Amazon | Academia/Industry | 2503.18278 | - |
| 10 | Accelerating Multimodel Large Language Models by Searching Optimal Vision Token Reduction | Shiyu Zhao | Rutgers University / Meta AI | Academia/Industry | 2412.00556 | - |
| 11 | ATP-LLaVA: Adaptive Token Pruning for Large Vision Language Models | Xubing Ye | Tsinghua University | Academia | 2412.00447 | - |
| 12 | DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models | Keda Tao | Northeastern University / Salesforce | Academia/Industry | 2411.15024 | - |
| 13 | VoCo-LLaMA: Towards Vision Compression with Large Language Models | Xubing Ye | Tsinghua University | Academia | 2406.12275 | - |
| 14 | VisionZip: Longer is Better but Not Necessary in Vision Language Models | Senqiao Yang | CUHK | Academia | 2412.04467 | - |

*Citations from Google Scholar as of search date. GS = Google Scholar count shown.

---

## Detailed Information by Paper

### ICCV 2025

#### 1. FALCON: Resolving Visual Redundancy and Fragmentation in High-resolution Multimodal Large Language Models via Visual Registers
- **First Author:** Renshan Zhang
- **Affiliation:** Shandong University, China
- **Co-authors:** Rui Shao, Gongwei Chen, Miao Zhang, Kaiwen Zhou, Weili Guan, Liqiang Nie
- **arXiv ID:** 2501.16297
- **Type:** Academia
- **Citations:** 16 (from Google Scholar)
- **Note:** Accepted to ICCV 2025

#### 2. Oasis: One Image is All You Need for Multimodal Instruction Data Synthesis
- **Status:** Not found on arXiv or Google Scholar with exact title match
- **Note:** May be under different title or not yet publicly available

#### 3. Growing a Twig to Accelerate Large Vision-Language Models
- **First Author:** Zhenwei Shao
- **Affiliation:** University of Science and Technology of China (USTC)
- **Co-authors:** Mingyang Wang, Zhou Yu, Wenwen Pan, Yan Yang, Tao Wei, Hongyuan Zhang, Ning Mao, Wei Chen, Jun Yu
- **arXiv ID:** 2503.14075
- **Type:** Academia
- **Note:** Accepted at ICCV 2025

#### 4. Multi-Granular Spatio-Temporal Token Merging for Training-Free Acceleration of Video LLMs
- **First Author:** Jeongseok Hyun
- **Affiliation:** Yonsei University, South Korea
- **Co-authors:** Sukjun Hwang, Su Ho Han, Taeoh Kim, Inwoong Lee, Dongyoon Wee, Joon-Young Lee, Seon Joo Kim, Minho Shim
- **arXiv ID:** 2507.07990
- **Type:** Academia
- **Note:** Accepted at ICCV 2025

#### 5. Dynamic-VLM: Simple Dynamic Visual Token Compression for VideoLLM
- **First Author:** Han Wang
- **Affiliation:** ByteDance
- **Co-authors:** Yuxiang Nie, Yongjie Ye, Deng GuanYu, Yanjie Wang, Shuai Li, Haiyang Yu, Jinghui Lu, Can Huang
- **arXiv ID:** 2412.09530
- **Type:** Industry (ByteDance)
- **Note:** May not be ICCV 2025 (arXiv doesn't list conference)

---

### CVPR 2025

#### 1. LION-FS: Fast & Slow Video-Language Thinker as Online Video Assistant
- **First Author:** Wei Li
- **Affiliation:** Harbin Institute of Technology, China
- **Co-authors:** Bing Hu, Rui Shao, Leyang Shen, Liqiang Nie
- **arXiv ID:** 2503.03663
- **Type:** Academia
- **Note:** Accepted to CVPR 2025

#### 2. A Stitch in Time Saves Nine: Small VLM is a Precise Guidance for Accelerating Large VLMs
- **First Author:** Wangbo Zhao
- **Affiliation:** National University of Singapore
- **Co-authors:** Yizeng Han, Jiasheng Tang, Zhikai Li, Yibing Song, Kai Wang, Zhangyang Wang, Yang You
- **arXiv ID:** 2412.03324
- **Type:** Academia
- **Note:** CVPR 2025

#### 3. PyramidDrop: Accelerating Your Large Vision-Language Models via Pyramid Visual Redundancy Reduction
- **First Author:** Long Xing
- **Affiliation:** Shanghai AI Laboratory / Chinese University of Hong Kong
- **Co-authors:** Qidong Huang, Xiaoyi Dong, Jiajie Lu, Pan Zhang, Yuhang Zang, Yuhang Cao, Conghui He, Jiaqi Wang, Feng Wu, Dahua Lin
- **arXiv ID:** 2410.17247
- **Type:** Academia/Industry (Shanghai AI Lab)
- **Note:** CVPR 2025

#### 4. Hybrid-Level Instruction Injection for Video Token Compression in Multi-modal Large Language Models
- **First Author:** Zhihang Liu
- **Affiliation:** Zhejiang University, China
- **Co-authors:** Chen-Wei Xie, Pandeng Li, Liming Zhao, Longxiang Tang, Yun Zheng, Chuanbin Liu, Hongtao Xie
- **arXiv ID:** 2503.16036
- **Type:** Academia
- **Note:** Accepted to CVPR 2025

#### 5. PACT: Pruning and Clustering-Based Token Reduction for Faster Visual Language Models
- **First Author:** Mohamed Dhouib
- **Affiliation:** Telecom Paris, Institut Polytechnique de Paris, France
- **Co-authors:** Davide Buscaldi, Sonia Vanier, Aymen Shabou
- **arXiv ID:** 2504.08966
- **Type:** Academia
- **Note:** Accepted to CVPR 2025

#### 6. DivPrune: Diversity-based Visual Token Pruning for Large Multimodal Models
- **First Author:** Saeed Ranjbar Alvar
- **Affiliation:** Huawei Noah's Ark Lab, Canada
- **Co-authors:** Gursimran Singh, Mohammad Akbari, Yong Zhang
- **arXiv ID:** 2503.02175
- **Type:** Industry (Huawei)
- **Note:** Accepted to CVPR 2025

#### 7. SynerGen-VL: Towards Synergistic Image Understanding and Generation with Vision Experts and Token Folding
- **First Author:** Hao Li
- **Affiliation:** Chinese University of Hong Kong / Shanghai AI Laboratory
- **Co-authors:** Changyao Tian, Jie Shao, Xizhou Zhu, Zhaokai Wang, Jinguo Zhu, Wenhan Dou, Xiaogang Wang, Hongsheng Li, Lewei Lu, Jifeng Dai
- **arXiv ID:** 2412.09604
- **Type:** Academia
- **Note:** CVPR 2025

#### 8. PVC: Progressive Visual Token Compression for Unified Image and Video Processing in Large Vision-Language Models
- **First Author:** Chenyu Yang
- **Affiliation:** Chinese University of Hong Kong / Shanghai AI Laboratory
- **Co-authors:** Xuan Dong, Xizhou Zhu, Weijie Su, Jiahao Wang, Hao Tian, Zhe Chen, Wenhai Wang, Lewei Lu, Jifeng Dai
- **arXiv ID:** 2412.09613
- **Type:** Academia
- **Note:** CVPR 2025

#### 9. TopV: Compatible Token Pruning with Inference Time Optimization for Fast and Low-Memory Multimodal Vision Language Model
- **First Author:** Cheng Yang
- **Affiliation:** Rice University / Amazon
- **Co-authors:** Yang Sui, Jinqi Xiao, Lingyi Huang, Yu Gong, Chendi Li, Jinghua Yan, Yu Bai, Ponnuswamy Sadayappan, Xia Hu, Bo Yuan
- **arXiv ID:** 2503.18278
- **Type:** Academia/Industry (Amazon)
- **Note:** Accepted by CVPR 2025

#### 10. Accelerating Multimodel Large Language Models by Searching Optimal Vision Token Reduction
- **First Author:** Shiyu Zhao
- **Affiliation:** Rutgers University / Meta AI
- **Co-authors:** Zhenting Wang, Felix Juefei-Xu, Xide Xia, Miao Liu, Xiaofang Wang, Mingfu Liang, Ning Zhang, Dimitris N. Metaxas, Licheng Yu
- **arXiv ID:** 2412.00556
- **Type:** Academia/Industry (Meta)
- **Note:** Technical report, CVPR 2025

#### 11. ATP-LLaVA: Adaptive Token Pruning for Large Vision Language Models
- **First Author:** Xubing Ye
- **Affiliation:** Tsinghua University, China
- **Co-authors:** Yukang Gan, Yixiao Ge, Xiao-Ping Zhang, Yansong Tang
- **arXiv ID:** 2412.00447
- **Type:** Academia
- **Note:** CVPR 2025

#### 12. DyCoke: Dynamic Compression of Tokens for Fast Video Large Language Models
- **First Author:** Keda Tao
- **Affiliation:** Northeastern University / Salesforce
- **Co-authors:** Can Qin, Haoxuan You, Yang Sui, Huan Wang
- **arXiv ID:** 2411.15024
- **Type:** Academia/Industry (Salesforce)
- **Note:** CVPR 2025

#### 13. VoCo-LLaMA: Towards Vision Compression with Large Language Models
- **First Author:** Xubing Ye
- **Affiliation:** Tsinghua University, China
- **Co-authors:** Yukang Gan, Xiaoke Huang, Yixiao Ge, Yansong Tang
- **arXiv ID:** 2406.12275
- **Type:** Academia
- **Note:** CVPR 2025

#### 14. VisionZip: Longer is Better but Not Necessary in Vision Language Models
- **First Author:** Senqiao Yang
- **Affiliation:** Chinese University of Hong Kong
- **Co-authors:** Yukang Chen, Zhuotao Tian, Chengyao Wang, Jingyao Li, Bei Yu, Jiaya Jia
- **arXiv ID:** 2412.04467
- **Type:** Academia
- **Note:** CVPR 2025

---

## Statistics

### By Type:
- **Academia only:** 12 papers
- **Industry only:** 2 papers (ByteDance, Huawei)
- **Academia/Industry collaboration:** 4 papers (Shanghai AI Lab, Amazon, Meta, Salesforce)

### By Institution (First Author):
**China:**
- Tsinghua University (2 papers)
- Chinese University of Hong Kong (3 papers)
- Zhejiang University (1 paper)
- Harbin Institute of Technology (1 paper)
- Shandong University (1 paper)
- USTC (1 paper)
- Shanghai AI Lab (2 papers)
- ByteDance (1 paper)
- Huawei (1 paper)

**Singapore:**
- National University of Singapore (1 paper)

**South Korea:**
- Yonsei University (1 paper)

**France:**
- Telecom Paris / IP Paris (1 paper)

**USA:**
- Rice University (1 paper)
- Rutgers University (1 paper)
- Northeastern University (1 paper)
- Amazon (1 paper)
- Meta (1 paper)
- Salesforce (1 paper)

### Industry Presence:
- ByteDance (1)
- Huawei (1)
- Meta (1)
- Amazon (1)
- Salesforce (1)

---

## Notes

1. **Citation counts** are limited because these are very recent 2025 papers. Most have not accumulated significant citations yet.
2. **Oasis paper** was not found in arXiv searches - it may be under a different title or not yet publicly released.
3. **Dynamic-VLM** was found on arXiv but not confirmed as ICCV 2025 (no conference listed).
4. Most papers are from Chinese institutions, reflecting the strong research activity in multimodal LLMs in China.
5. Several papers have cross-institutional collaborations between universities and industry labs (Shanghai AI Lab, Meta, Amazon, Salesforce).

---

*Last updated: February 12, 2026*
*Search sources: arXiv API, Google Scholar*
